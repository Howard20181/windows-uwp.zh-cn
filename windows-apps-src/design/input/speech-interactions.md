---
Description: 使用 Cortana 语音命令、语音识别和语音合成，将语音整合到你的应用中。
title: 语音交互
ms.assetid: 646DB3CE-FA81-4727-8C21-936C81079439
label: Speech interactions
template: detail.hbs
keywords: 语音，语音，语音识别，自然语言，听写，输入，用户交互
ms.date: 02/08/2017
ms.topic: article
ms.localizationpriority: medium
ms.openlocfilehash: fd33720255a04ffd8669673f027973afb4369086
ms.sourcegitcommit: 26bb75084b9d2d2b4a76d4aa131066e8da716679
ms.translationtype: MT
ms.contentlocale: zh-CN
ms.lasthandoff: 01/06/2020
ms.locfileid: "75684212"
---
# <a name="speech-interactions"></a>语音交互

将语音识别和文本到语音转换（又称 TTS 或语音合成）直接集成到你的应用的用户体验中。

**语音识别**对于文本听写，将用户说出的话语转换为用于表单输入的文本，从而指定操作或命令并完成任务。 既支持用于自由文本听写和 Web 搜索的预定义语法，也支持使用语音识别语法规范 (SRGS) 版本 1.0 创作的自定义语法。

**TTS** TTS 使用语音合成引擎（语音）将文本字符串转换为语音字词。 输入字符串既可以是基本的未经处理的文本，也可以是更复杂的语音合成标记语言 (SSML)。 SSML 提供用于控制语音输出特征（例如发音、音量、音调、音速和重读）的标准方式。

**其他语音相关组件：** 
Windows 应用程序中的 **Cortana** 使用自定义语音命令（说出或键入）在前台启动你的应用（应用获得焦点，就好像是从“开始”菜单启动一样）或者作为一项后台任务而运行（**Cortana** 保持焦点，但提供来自应用的结果）。 如果要使用 **Cortana** UI 公开应用功能，请参阅 [Cortana 语音命令 (VCD) 指南](https://docs.microsoft.com/cortana/voice-commands/vcd)。

## <a name="speech-interaction-design"></a>语音交互设计

经过周密地设计和实现，语音可以成为用户与应用交互的可靠而愉快的方式，补充甚至替代键盘、鼠标、触摸和手势。

这些指南和建议将介绍如何以最佳方式将语音识别和 TTS 都集成到你的应用的交互体验中。

如果你考虑在你的应用中支持语音交互：

-   可以通过语音执行哪些操作？ 用户是否可以在页面之间导航、调用命令，或将数据作为文本字段、简短注释或长消息输入？
-   语音输入是否是用于完成任务的理想选项？
-   用户如何知道语音输入可用？
-   应用是否始终在侦听，或者用户是否需要执行某项操作才能使应用进入侦听模式？
-   哪些短语会启动操作或行为？ 是否需要在屏幕上枚举短语和操作？
-   是否需要提示、确认和消除歧义屏幕或 TTS？
-   应用和用户之间的交互对话框是什么？
-   你的应用上下文是否需要自定义词汇或有限词汇（如医学、科学或区域设置）？
-   是否需要网络连接？

## <a name="text-input"></a>文本输入

用于文本输入的语音包括简短形式（单个词或短语）和较长形式（连续听写）。 简短形式输入的长度必须小于 10 秒，而较长形式的输入会话最长可达两分钟。 （较长格式输入可以重新启动而无需用户干预，给人连续听写的印象。）

你应该提供视觉提示，以指示语音识别受到支持并可供用户使用，以及用户是否需要打开它。 例如，一个带麦克风标志的命令栏按钮（请参阅[命令栏](../controls-and-patterns/app-bars.md)）可用于同时显示可用性和状态。

提供正在进行的识别反馈，尽量减少执行识别时任何明显的响应缺失。

让用户使用键盘输入、消除歧义提示、建议或其他语音识别方式修改识别文本。

如果从除语音识别以外的其他设备（如触摸或键盘）检测到输入，请停止识别。 这很可能表示用户已转到其他任务，如更正识别文本或与其他表单字段交互。

指定无任何语音输入指示识别已结束的时长。 请不要在这段时间后自动重新启动识别，因为它通常指示用户已停止与你的应用交互。

如果网络连接不可用，则禁用所有连续识别 UI 并终止识别会话。 连续识别需要网络连接。

## <a name="commanding"></a>命令处理

语音输入可以启动操作、调用命令和完成任务。

如果空间允许，请考虑通过有效输入示例，显示当前应用上下文支持的响应。 这可以减少你的应用需要处理的潜在响应，还可以消除用户的困惑。

努力整理你的问题，尽可能提出如响应一样具体的问题。 例如“你今天想做什么？” 是一个开放性问题，由于响应可能截然不同，它将需要庞大的语法定义。 此外，“你想要玩游戏还是听音乐呢？” 这一问题通过相应的狭小语法定义将响应限制在二选一的有效答案中。 狭小语法定义的创作过程容易得多，它还可以产生准确得多的识别结果。

当语音识别置信度较低时，请求用户确认。 如果用户的意图并不明确，最好获得清楚示意，而不是启动意外操作。

你应该提供视觉提示，以指示语音识别受到支持并可供用户使用，以及用户是否需要打开它。 例如，一个带麦克风标志的命令栏按钮（请参阅[命令栏指南](../controls-and-patterns/app-bars.md)）可用于同时显示可用性和状态。

如果语音识别开关总是位于视图以外，请考虑在应用的内容区域中显示状态指示器。

如果识别由用户启动，为保证一致性，请考虑使用内置识别体验。 内置体验包含可借助提示、示例、消除歧义、确认和错误进行自定义的屏幕。

屏幕根据指定的约束而异：

-   预定义语法（听写或 Web 搜索）

    -   **侦听**屏幕。
    -   **思考**屏幕。
    -   **听到你说**屏幕或错误屏幕。
-   字词或短语列表，或者 SRGS 语法文件

    -   **侦听**屏幕。
    -   **你说的是**屏幕，如果用户所说的内容可以解释为不止一种可能性结果。
    -   **听到你说**屏幕或错误屏幕。

在**侦听**屏幕上，你可以：

-   自定义标题文本。
-   提供用户可以说出的示例文本。
-   指定是否显示**听到你说**屏幕。
-   在**听到你说**屏幕上向用户读出已识别的字符串。

以下示例显示了使用 SRGS 定义的约束的语音识别器的内置识别流程。 在本例中，语音识别是成功的。

![基于 sgrs 语法文件的约束的初始识别屏幕](images/speech/speech-listening-initial.png)

![基于 sgrs 语法文件的约束的中间识别屏幕](images/speech/speech-listening-intermediate.png)

![基于 sgrs 语法文件的约束的最终识别屏幕](images/speech/speech-listening-complete.png)

## <a name="always-listening"></a>始终聆听

只要应用已启动，你的应用就可以聆听和识别语音输入，无需用户干预。

你应该基于应用上下文自定义语法约束。 这可使语音识别体验具有很高的针对性，始终与当前任务保持相关，并最大程度地减少错误。

## <a name="what-can-i-say"></a>“我可以说什么？”

启用语音输入后，帮助用户了解可以准确理解哪些内容，以及可以执行哪些操作十分重要。

如果语音识别由用户启用，请考虑使用命令栏或菜单命令来显示当前上下文支持的所有单词和短语。

如果语音识别始终处于打开状态，请考虑将短语“我可以说什么？” 添加到每个页面上。 当用户说出此短语时，显示当前上下文支持的所有单词和短语。 使用此短语将为用户在系统上发现语音功能提供一种一致的方式。

## <a name="recognition-failures"></a>识别失败

语音识别将失败。 在音频质量较差、仅识别出一部分短语或根本没有检测到任何输入时，将发生故障。

请妥善处理故障，帮助用户了解识别失败的原因并恢复。

你的应用应该通知用户无法理解他们所说内容，需要他们重试。

请考虑提供一个或多个受支持短语示例。 用户有可能重复说出建议的短语，这可增加识别成功率。

你应显示一个包含可能匹配的列表，以供用户选择。 这可能远比重新执行识别过程有效。

你应始终支持替代输入类型，它们对于处理重复识别故障尤其有用。 例如，你可以建议用户尝试使用键盘、触摸或鼠标从可能的匹配列表中进行选择。

请使用内置语音识别体验，因为它包含了用于告知用户识别未成功的屏幕，并让用户再次进行识别尝试。

聆听并尝试改正音频输入问题。 语音识别器可以检测音频质量问题，该问题可反作用于语音识别准确度。 你可以使用语音识别器提供的信息，将该问题告知用户并让其采取改正措施（如果可以）。 例如，如果麦克风的音量设置太低，则可以提示用户说话声应更响亮或调高音量。

## <a name="constraints"></a>约束

约束（或语法）定义语音识别器可匹配的语音字词和短语。 你可以指定一种预定义 Web 服务语法，也可以创建一种随你的应用一起安装的自定义语法。

### <a name="predefined-grammars"></a>预定义的语法

预定义的听写和 Web 搜索语法在无需你创作语法的情况下为你的应用提供语音识别。 使用这些语法时，语音识别由远程 Web 服务执行，并且结果将返回到设备

-   默认自由文本听写语法可以识别用户以特定语言说出的大部分字词或短语，并且为识别短语进行了优化。 当你不希望限制用户可说内容的种类时，自由文本听写非常有用。 典型用法包括为一条消息创建笔记或听写其内容。
-   诸如听写语法等 Web 搜索语法包含了用户可能说出的大量字词和短语。 但是，优化它的目的是识别用户搜索 Web 时通常使用的术语。

> [!NOTE]
> 由于预定义的听写和 Web 搜索语法可能很大，而且处于联机状态（不在设备上），性能可能不如安装在设备上的自定义语法快。

可以使用这些预定义语法识别长达 10 秒的语音输入，并且不要求你进行任何创作。 然而，它们确实需要连接到网络。

### <a name="custom-grammars"></a>自定义语法

自定义语法由你设计和创作，随你的应用一起安装。 使用自定义约束的语音识别是在设备上执行的。

-   编程列表约束提供一种轻型方法，用于使用字词或短语的列表创建一种简单的语法。 列表约束非常适用于识别清晰的短语。 因为语音识别引擎仅须处理语音即可确认匹配，所以采用某种语法明确指定所有字词也可提高识别准确度。 也可以以编程方式更新该列表。
-   SRGS 语法是一个静态文档，与编程列表约束不同，它使用由 [SRGS 版本 1.0](https://www.w3.org/TR/speech-grammar/) 定义的 XML 格式。 SRGS 语法提供了对语音识别体验的最大控制，方法是让你在单个识别中捕获多个语义含义。

    以下是用于编写 SRGS 语法的一些提示：

    -   使每个语法保持简短。 与包含许多短语的较大语法相比，包含较少短语的语法往往可提供更准确的识别度。 最好将多个较小语法用于特定方案，而不是将单个语法用于整个应用。
    -   让用户了解针对每个应用上下文说哪些内容，并按照需要启用和禁用语法。
    -   设计每个语法，以便用户可以使用多种方式说出同一条命令。 例如，可以使用 **GARBAGE** 规则来匹配你的语法没有定义的语音输入。 这将使用户可以说出对你的应用没有任何意义的其他字词。 例如，“给我”、“和”、“呃”、“可能”等等。
    -   使用 [sapi:subset](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/jj572474(v=office.14)) 元素，帮助匹配语音输入。 这是针对 SRGS 规范的 Microsoft 扩展，可帮助匹配部分短语。
    -   尽量避免在语法中定义只包含一个音节的短语。 对于包含两个或更多音节的短语，识别往往更为准确。
    -   避免使用听起来相似的短语。 例如，“hello”、“bellow”和“fellow”等短语可使识别引擎难以分辨，从而导致较差的识别准确度。

> [!NOTE]
> 使用哪种类型的约束类型取决于待创建识别体验的复杂程度。 对于特定识别任务，任一类型都可能是最佳选择，你也可能在应用中发现所有类型的约束的用途。

### <a name="custom-pronunciations"></a>自定义发音

如果你的应用包含了带有不常见或虚构字词的专用词汇或带有罕见发音的字词，你可能能够通过定义自定义发音来提高对这些字词的识别性能。

对于包含字词和短语的小型列表，或包含不常用字词和短语的列表，可以使用 SRGS 语法创建自定义发音。 有关详细信息，请参阅[令牌元素](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361600(v=office.14))。

对于包含字词和短语的较大列表，或包含常用字词和短语的列表，可以创建单独的发音词典文档。 有关详细信息，请参阅[关于词典和音标字母](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh361646(v=office.14))。

## <a name="testing"></a>测试

通过应用目标受众测试语音识别准确度以及任何支持的 UI。 这是确定应用的语音交互体验有效性的最佳方式。 例如，用户是否因你的应用无法聆听常见短语而获得了较差的识别结果？

可以修改语法以支持此短语，或者为用户提供受支持短语的列表。 如果已提供受支持短语列表，请确保它易被发现。

## <a name="text-to-speech-tts"></a>文本到语音转换 (TTS)

TTS 从纯文本或 SSML 生成语音输出。

尝试设计礼貌且具有鼓励性的提示。

请考虑是否应阅读长字符串文本。 聆听文本消息是一回事，但聆听由难以记住的搜索结果组成的冗长列表完全是另一回事。

你应该提供媒体控件，以便用户暂停或停止 TTS。

你应聆听所有 TTS 字符串，确保它们明白易懂，听起来自然。

-   将一系列不常见单词串联在一起，或者说出零件编号或标点可能会导致短语变得无法识别。
-   当母语使用者说出短语时的韵律或节奏不同时，语音可能听起来不自然。

可以使用 SSML 而不是纯文本作为语音合成器的输入来解决这两个问题。 有关 SSML 的详细信息，请参阅[使用 SSML 控制合成的语音](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh378454(v=office.14))和[语音合成标记语言参考](https://docs.microsoft.com/previous-versions/office/developer/speech-technologies/hh378377(v=office.14))。

## <a name="other-articles-in-this-section"></a>本部分中的其他文章 

| 主题 | 描述 |
| --- | --- |
| [语音识别](speech-recognition.md) | 使用语音识别提供输入内容、指定操作或命令并完成任务。 |
| [指定语音识别器语言](specify-the-speech-recognizer-language.md) | 了解如何选择要用于语音识别的安装语言。 |
| [定义自定义识别约束](define-custom-recognition-constraints.md) | 了解如何为语音识别定义和使用自定义约束。 |
| [启用连续听写](enable-continuous-dictation.md) |了解如何捕获和识别较长的连续听写语音输入。 |
| [管理音频输入的问题](manage-issues-with-audio-input.md) | 了解如何管理由音频输入质量所导致的语音识别准确度问题。 |
| [设置语音识别超时](set-speech-recognition-timeouts.md) | 设置语音识别器忽略静音或无法识别的声音（干扰）并继续侦听语音输入的时长。 |

## <a name="related-articles"></a>相关文章

* [语音交互](https://docs.microsoft.com/windows/uwp/input-and-devices/speech-interactions)
* [Cortana 交互](https://docs.microsoft.com/windows/uwp/input-and-devices/cortana-interactions)

 **示例**

* [语音识别和语音合成示例](https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/SpeechRecognitionAndSynthesis)
 

 



